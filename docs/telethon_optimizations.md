# Telethon-based optimizations for TOBS

TL;DR

- –≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–µ—Ä–µ—á–∏—Å–ª—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–∞ –±–∞–∑–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π Telethon –∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã TOBS.
- –§–æ–∫—É—Å: —É–º–µ–Ω—å—à–µ–Ω–∏–µ I/O, —ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏, —É–≤–µ–ª–∏—á–µ–Ω–∏–µ throughput (msg/s), —É–ª—É—á—à–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–µ–¥–∏–∞.
- –ö–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç: –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –ø–æ—á–µ–º—É —ç—Ç–æ –ø–æ–º–æ–∂–µ—Ç, trade-offs, –≥–¥–µ –º–µ–Ω—è—Ç—å –∫–æ–¥ (—Ñ–∞–π–ª—ã –∏ —Å—Ç—Ä–æ–∫–∏), –∏ –∫–∞–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å/–æ—Ü–µ–Ω–∏–≤–∞—Ç—å –≤–ª–∏—è–Ω–∏–µ.

Goals

- –ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–ø—É—Å–∫–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å (—Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É).
- –£–º–µ–Ω—å—à–∏—Ç—å peak memory –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –±–æ–ª—å—à–∏—Ö —á–∞—Ç–æ–≤.
- –°–Ω–∏–∑–∏—Ç—å –ª–∏—à–Ω–∏–µ syscalls –∏ —Å–µ—Ç–µ–≤–æ–π —Ç—Ä–∞—Ñ–∏–∫ (–º–µ–Ω—å—à–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö –∑–∞–≥—Ä—É–∑–æ–∫).
- –ú–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫/pauses (FloodWait / DC migration).

---

## High-priority optimizations (High impact, low/medium risk)

1. –ë–∞—Ç—á–µ–≤—ã–π fetch —Å–æ–æ–±—â–µ–Ω–∏–π –≤ `TelegramManager` (iter_messages ‚Üí get_messages)

- –ì–¥–µ: `tobs/src/telegram_client.py#L320-370`
- –ß—Ç–æ: –∑–∞–º–µ–Ω–∏—Ç—å per-message `iter_messages` –Ω–∞ –ø–∞–∫–µ—Ç–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π `get_messages(limit=100)`, –∏ yield —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –±–∞—Ç—á–µ–π.
- –ü–æ—á–µ–º—É: —É–º–µ–Ω—å—à–µ–Ω–∏–µ Python-level await/overhead –Ω–∞ –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Üí —É–≤–µ–ª–∏—á–µ–Ω–∏–µ throughput.
- Trade-offs: –Ω—É–∂–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å offset_id/min_id/reverse, –∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å batch_size (default 100 = Telethon limit).
- –ö–∞–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å: unit test –¥–ª—è fetch_messages –Ω–∞ –º–∞–ª—ã—Ö/–±–æ–ª—å—à–∏—Ö —á–∞—Ç–∞—Ö; benchmark: msg/sec –∏ requests/msg.

2. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –º–µ–¥–∏–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ file-id

- –ì–¥–µ: `tobs/src/media/downloader.py#L292-356` –∏ `tobs/src/media/manager.py`
- –ß—Ç–æ: –ø–µ—Ä–µ–¥ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å, –±—ã–ª –ª–∏ —É–∂–µ —Å–∫–∞—á–∞–Ω —Ç–æ—Ç –∂–µ —Ñ–∞–π–ª –ø–æ `message.media.document.id` –∏–ª–∏ –ø–æ `photo.id` –∏ `access_hash` ‚Äî —Ö—Ä–∞–Ω–∏—Ç—å map `file_key -> local_path`.
- –ü–æ—á–µ–º—É: –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö —Å–∫–∞—á–∏–≤–∞–Ω–∏–π –º–µ–¥–∏–∞ (—Ä–µ–ø–æ—Å—Ç—ã/–ø–µ—Ä–µ—Å—ã–ª–∫–∏), —É–º–µ–Ω—å—à–∏—Ç—å —Å–µ—Ç–µ–≤–æ–π —Ç—Ä–∞—Ñ–∏–∫ –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏—Å–∫–∞.
- Trade-offs: –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏ –Ω–∞–¥–µ–∂–Ω—ã–π `file_key`. –ü–ª—é—Å ‚Äî –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã `cache_manager` –¥–ª—è re-use –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ.
- –ö–∞–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å: unit-test –¥–ª—è MediaDownloader: 2 —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–Ω–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç —Ç–æ—Ç –∂–µ path –∏ –Ω–µ –¥—É–±–ª–∏—Ä—É—é—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ.

3. –°–∂–∞—Ç–∏–µ/–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ (IO overhead)

- –ì–¥–µ: `tobs/src/telegram_sharded_client.py#L420-640` (`_fetch_chunk`) –∏ `tobs/src/telegram_sharded_client.py#L860-980` (merge)
- –ß—Ç–æ: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `zlib` –∏–ª–∏ `orjson`+msgpack compression –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ chunk'–æ–≤; –æ–ø—Ü–∏—è: —Å–µ—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–æ–æ–±—â–µ–Ω–∏–π (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è metadata) –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω—ã—Ö `Message` –æ–±—ä–µ–∫—Ç–æ–≤.
- –ü–æ—á–µ–º—É: —É–º–µ–Ω—å—à–µ–Ω–∏–µ IO –ø—Ä–∏ –∑–∞–ø–∏—Å–∏/—á—Ç–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ ‚Üí –º–µ–Ω–µ–µ –∑–∞—Ç—Ä–∞—Ç–Ω—ã–π merge ‚Üí –º–µ–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —ç–∫—Å–ø–æ—Ä—Ç.
- Trade-offs: CPU overhead –¥–ª—è –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏; –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∏–µ `Message` –Ω–∞ merge –ø–æ—Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö API-–∑–∞–ø—Ä–æ—Å–æ–≤ (re-fetch), –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ meta.
- –ö–∞–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å: —Å—Ä–∞–≤–Ω–∏—Ç—å bytes written, merge time –∏ total time —Å/–±–µ–∑ —Å–∂–∞—Ç–∏—è.

---

## Medium-priority optimizations (Moderate impact)

4. –ü–µ—Ä–µ—Å–º–æ—Ç—Ä timeout/await –º–æ–¥–µ–ª–∏ –∏ `wait_time` –≤ `iter_messages`

- –ì–¥–µ: `tobs/src/telegram_client.py#L320-370`
- –ß—Ç–æ: –∑–∞–º–µ–Ω–∏—Ç—å per-message `asyncio.wait_for` –Ω–∞ batch-level timeouts (timeout for get_messages) ‚Äî —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ per-message await overhead.
- –ü–æ—á–µ–º—É: —É–º–µ–Ω—å—à–µ–Ω–∏–µ overhead –Ω–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏ —Ç–∞–π–º–∞—É—Ç—ã, —É–ø—Ä–æ—â–µ–Ω–∏–µ –ª–æ–≥–∏–∫–∏ retries.
- Trade-offs: –Ω—É–∂–Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å edge-cases: slow network, single message stall.

5. –°–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö/—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è shard ‚Üí master: lightweight schema

- –ì–¥–µ: `tobs/src/telegram_sharded_client.py#L420-640` ‚Äî pickle -> minimal schema
- –ß—Ç–æ: –≤ worker —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å–∂–∞—Ç—É—é –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–æ–±—â–µ–Ω–∏–π (id, sender_id, date, text, media_meta), –∞ master –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ rehydrate —Å–æ–æ–±—â–µ–Ω–∏—è.
- –ü–æ—á–µ–º—É: –º–∞–ª–µ–Ω—å–∫–∏–π payload –Ω–∞ –¥–∏—Å–∫, –º–µ–Ω—å—à–µ IO.
- Trade-offs: master –Ω–µ —Å–º–æ–∂–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å `download_media` –Ω–∞–ø—Ä—è–º—É—é –Ω–∞ —Ç–µ—Ö –æ–±—ä–µ–∫—Ç–∞—Ö; –≤–æ–∑–º–æ–∂–Ω—ã re-fetches –¥–ª—è media download. –≠—Ç–æ –ø–æ–¥—Ö–æ–¥ –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è: worker —Å–∫–∞—á–∏–≤–∞–µ—Ç –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç/–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–µ–¥–∏–∞, –º–∞—Å—Ç–µ—Ä —Ç–æ–ª—å–∫–æ –ø–∏—à–µ—Ç —Ç–µ–∫—Å—Ç.

6. Autotuning `part_size_kb` and download concurrency

- –ì–¥–µ: `tobs/src/media/downloader.py#L440` (download_file) and `class MediaDownloader`
- –ß—Ç–æ: –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞—Ç—å `part_size_kb` based on file size & connection; expose as config/env var.
- –ü–æ—á–µ–º—É: –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è chunk size —Å–Ω–∏–∂–∞–µ—Ç request overhead or improves throughput (varies per environment).
- Trade-offs: requires benchmarking across NVMe/NAS/HDD and network conditions.

7. Metadata caching and `GetFullChannelRequest` for message counts

- –ì–¥–µ: `tobs/src/telegram_client.py#L970-989` (get topic message count) and other places that read `total` counts.
- –ß—Ç–æ: use `GetFullChannelRequest` and `client.get_entity` for stable metadata (if available), and fallback to `get_messages(limit=0)`.
- –ü–æ—á–µ–º—É: sometimes `get_messages(limit=0)` is ambiguous; full channel info may return official totals.

---

## Low-priority optimizations (Lower immediate impact; potential edge benefits)

8. Persist BloomFilter options vs exact IDs

- –ì–¥–µ: `tobs/src/export/exporter.py#L100-180` (EntityCacheData)
- –ß—Ç–æ: make storing of the BloomFilter optionally persistent (store bitarray compressed to disk), OR provide an exact 'processed IDs' LRU for safe resume.
- Trade-offs: BloomFilter false positives might hide messages on resume. Decide by use-case (safety vs speed).

9. Reduce logging overhead / add log rate-limits

- –ì–¥–µ: `tobs/src/export/exporter.py#L468-520` `_lazy_log` ‚Äî batched logging
- –ß—Ç–æ: make `log_batch_interval` and thresholds config-driven; add heuristics to reduce logging in high-throughput runs.
- Trade-offs: less actionable logs during debug runs; keep telemetry for monitoring.

10. DC-aware worker assignment and pre-warming

- –ì–¥–µ: `tobs/src/telegram_sharded_client.py` (DC detection with `self._extract_dc_id`) and worker setup
- –ß—Ç–æ: route chunk tasks to the worker with the closest DC, and pre-connect worker clients in a warm pool to avoid initiation latency.
- Trade-offs: requires mapping sessions to datacenter info; complexity grows slightly.

---

## Testing & Benchmarks (How to measure effect)

- Add a small benchmarking harness (in `tests/benchmarks/`):
    - Target chat sizes: 1k, 10k, 50k, 100k messages.
    - Metric: total time, msg/sec, peak memory, total network bytes read, number of API requests
    - For media: also MB/sec, average file download time, and disk io per file
- Unit tests for each optimization:
    - `fetch_messages` equivalence (chunk-based vs iter) using a mock Telethon client.
    - Media dedupe test: 2 messages referencing same document return same local path.
    - Sharded serialization round-trip (worker writes, merge reads) verify no data loss and integrity.

---

## Implementation checklist for PRs

- [ ] Add config options for any new tuning variables (PREFETCH_BATCH_SIZE, PART_SIZE_KB, COMPRESSION_ENABLED, etc.) in `.env.example` and config struct.
- [ ] Implement changes incrementally: unit-tests, then integration+benchmark.
- [ ] Run benchmark suite vs baseline and record metrics.
- [ ] Update performance guide `PERFORMANCE_GUIDE.md` with recommended defaults.
- [ ] Add basic metrics/monitoring for new features (e.g., dedupe cache hits/misses, compressed chunks saved bytes).

---

## Next Steps (recommended first two items)

- Implement `get_messages` batch-based generator in `TelegramManager.fetch_messages` and add tests.
- Implement `MediaDownloader` dedupe by `file_key` and persist cache into `cache_manager`.

_Notes: Line references are approximate ‚Äî please verify during implementation; they've been added to help navigation._

## Benchmarks and performance verification

- Baseline: run export for small/medium/large test chats, save logs and metrics (time, throughput, memory, IO, API requests).
- Measure: Before and After for every optimization; use benchmarking harness in `tests/benchmarks/`.
- Baseline scripts (conceptual):
    - `python scripts/benchmark_export.py --target test_chat_10k --mode baseline` (captures logs and metrics)
    - Rerun with optimizations toggled ON and produce comparison CSV.

## Definition of Done (DoD) for each PR

- Unit tests covering core logic.
- Integration test that asserts no message loss on a 1k-message chat.
- Benchmark results show measurable improvement (or neutral) for the given prioritized metric.
- Configuration knobs added to `.env.example`.
- Documentation updated: `PERFORMANCE_GUIDE.md` and this doc (telethon_optimizations.md).

## PR Review & Testing checklist

- [ ] Linting and py_compile passes
- [ ] Unit tests for core logic added/updated
- [ ] Benchmark script outputs included in PR description (baseline vs new)
- [ ] Potential fallbacks for reliability (e.g., return to iter_messages when something fails)

## Step-by-step Implementation Plan (top items)

### 1) Batch fetch messages (TelegramManager)

1. Add a config option for `BATCH_FETCH_SIZE` (default 100).
2. Write helper `get_messages_batch_generator(entity, min_id, batch_size)` in `TelegramManager`.
3. Replace `iter_messages` usage in `fetch_messages` with a generator built on `get_messages`.
4. Add unit tests/mocks to validate semantics: no duplicates, correct ordering, correct stops at `min_id`.
5. Run benchmark, tune `BATCH_FETCH_SIZE` and `request_delay` options.
6. Document in report.

### 2) Media dedupe in downloader

1. Add `downloaded_cache` dict (in-memory per-run + persist via cache_manager).
2. Create stable `file_key` by prioritizing `document.id + access_hash`, fallback to `photo.id`, fallback to `message.file.name + file.size`.
3. Before starting download, check `downloaded_cache`, return existing path if match.
4. After successful download, persist to `cache_manager` with `key = file_key`.
5. Add tests for dedupe logic, including cross-run persistence test (cache manager stubbed).

### 3) Compress shard chunk data

1. Add config flag `SHARD_COMPRESSION_ENABLED` and compression level.
2. In `_fetch_chunk`: `zlib.compress(pickle.dumps(...), level=config.compression_level)` while writing.
3. In `fetch_messages` merging: `pickle.loads(zlib.decompress(body))`.
4. Add new unit test: create synthetic chunk, compress, merge, validate messages round-trip.
5. Add benchmark to measure disk IO/merge times with/without compression.

## Feature: Export Reactions (implementation plan)

Goal

- –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∞–∫—Ü–∏–π (summary) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –ø–æ—Å—Ç–∞–≤–∏–≤—à–∏—Ö —Ä–µ–∞–∫—Ü–∏—é.

Telethon resources / types (reference)

- `Message.reactions` (type `types.MessageReactions`) ‚Äî summary (counts, emoji types) may be present on `Message`.
- `types.MessagePeerReaction` / `types.MessageReactions` ‚Äî to inspect individual reactors where available.
- Optional API: `messages.getMessageReactionList` (if available via Telethon functions) ‚Äî to fetch detailed list of reactors for a message.

Implementation steps

1. Add config flags: `EXPORT_REACTIONS` (default False), `EXPORT_REACTORS_FULL` (default False).
2. Minimal (cheap) path: Read `message.reactions` directly during `_process_message_parallel` and add a line in the message export (eg. `Reactions: üëç2 ‚ù§Ô∏è1`).

- File: `tobs/src/export/exporter.py#L660-724` (where processing occurs)

3. Detailed (optional): For `EXPORT_REACTORS_FULL`, fetch per-message reactor list via API if needed:

- Use `functions.messages.GetMessageReactionListRequest` (if present) or Telethon helper to fetch reactors.
- This is API-expensive; implement caching (LRU, per-entity) and run in parallel with `Semaphore`.

4. Cache/metrics: record `reactions` counts in `EntityReporter` (metrics), also add counters for `reactions_api_calls`, `reactions_cache_hits`.
5. Sharding: if `EXPORT_REACTORS_FULL` enabled in sharded mode, run reactors fetch on workers (along with messages) to avoid extra master step.
6. Output format: add reaction summary inline in message text; optionally create `reactions.csv` or JSON side-file for structured analysis.

Trade-offs and notes

- Basic summary is cheap (only reading the field on `Message` if Telethon returned it); detailed user lists require additional API calls and must be optional.
- For privacy-conscious exports, allow `EXPORT_REACTORS_REDIRECT` to export user-id only or user-opaque fields (avoid personal data).

---

## Feature: Forum improvements & Topic export (implementation plan)

Goal

- –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ä—É–º—ã –∏ —Ç–æ–ø–∏–∫–∏ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã/–ø–∞–ø–∫–∏; –≤–∫–ª—é—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–æ–ø–∏–∫–∞, —Å–æ–æ–±—â–µ–Ω–∏—è —Ç–æ–ø–∏–∫–∞, –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É/—É—á–∞—Å—Ç–Ω–∏–∫–æ–≤.

Telethon resources / types (reference)

- `functions.messages.GetForumTopicsRequest` ‚Äî Telethon wrapper –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ç–æ–ø–∏–∫–æ–≤ —Ñ–æ—Ä—É–º–∞.
- `GetHistoryRequest` / `client.get_messages(entity, reply_to=topic_id)` ‚Äî –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–æ–ø–∏–∫–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–∞–∫–∂–µ `reply_to` –≤ Telethon).
- `types.ForumTopic` ‚Äî —Å–æ–¥–µ—Ä–∂–∏—Ç id, title, date, pinned/closed flags.

Implementation steps

1. Add `ExportTarget` type for forum topic selection or reuse existing `forum_topic` option (already exists in exporter flow).
2. Implement `_export_forum_topic()` in `Exporter`:
    - Create folder `export_path/<forum_name>/topics/` and file `topic_<topic_id>.md` per topic or `topic_<safe_title>.md`.
    - Use `TelegramManager.get_forum_topics(entity)` to list topics (already in code).
    - Use generator: `telegram_manager.fetch_messages(entity, limit=None, min_id=None, reply_to=topic_id)` or `client.get_messages(entity, reply_to=topic_id)` to fetch messages for topic; process them via `_process_message_parallel`.
    - Include topic metadata at top of file (title, creator, date, pinned/closed, message_count).
3. Permissions/Visibility: ensure `GetForumTopicsRequest` is wrapped in `connection_manager.execute_with_retry` (similar to other calls) and add fallback if forum is private.
4. Pagination and very large topics: support pagination via `page/offset` (lazy) or sharding per topic if extremely large.
5. Indexing & metadata: create `index.md` for forum that lists topics with message counts and export file path.
6. Optional: For each topic, provide a `topic_metrics.json` file with aggregated stats (views, reactions, poll results in the topic).

Sharding and concurrency

- For large topics, re-use shard manager logic: spawn workers to fetch topic ID range using `_worker_task` and chunking, then merge results as usual. This allows consistent tooling for both channel-level and topic-level exports.

How to integrate into exporter

- The current `_export_forum()` in `tobs/src/export/exporter.py#L1168-1180` is the correct entry point; replace the `pass` with iterating through `all_topics` and call `_export_forum_topic` per topic.

Tests

- Unit test for `get_forum_topics()` returns topics list (mock `GetForumTopicsRequest`).
- Integration test for `_export_forum()` exports per-topic files and counts (simulate a small forum in tests or with mocked client).
