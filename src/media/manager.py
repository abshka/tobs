"""
Media processor manager.

Main orchestrator that coordinates all media processing operations.
Uses composition of modular components instead of inheritance.
"""

import asyncio
import os
import shutil
import tempfile
import time
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import aiofiles
import aiofiles.os
from loguru import logger
from telethon.tl.types import Message

from src.utils import sanitize_filename

from .cache import MediaCache
from .download_queue import MediaDownloadQueue
from .downloader import MediaDownloader
from .hardware import HardwareAccelerationDetector
from .metadata import MetadataExtractor
from .models import ProcessingSettings, ProcessingTask
from .processors.audio import AudioProcessor
from .processors.image import ImageProcessor
from .processors.video import VideoProcessor
from .validators import MediaValidator


class MediaProcessor:
    """
    –ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –º–µ–¥–∏–∞-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–º–ø–æ–∑–∏—Ü–∏—é –º–æ–¥—É–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞.
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º API.
    """

    def __init__(
        self,
        config,
        client,
        cache_manager=None,
        connection_manager=None,
        max_workers: int = 4,
        temp_dir: Optional[Path] = None,
        enable_smart_caching: bool = True,
        worker_clients: list = None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–¥–∏–∞-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞.

        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            client: Telegram –∫–ª–∏–µ–Ω—Ç
            cache_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            connection_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            max_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            temp_dir: –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            enable_smart_caching: –í–∫–ª—é—á–∏—Ç—å —É–º–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
            worker_clients: –°–ø–∏—Å–æ–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ (–≤–æ—Ä–∫–µ—Ä–æ–≤)
        """
        self.config = config
        self.client = client
        self.worker_clients = worker_clients or []
        self.cache_manager = cache_manager
        self.connection_manager = connection_manager
        self.max_workers = max_workers
        self.temp_dir = temp_dir or Path(tempfile.gettempdir()) / "tobs_media"
        self.enable_smart_caching = enable_smart_caching

        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.temp_dir.mkdir(exist_ok=True)

        # –ü—É–ª—ã –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ–ø–µ—Ä–∞—Ü–∏–π
        self.io_executor = ThreadPoolExecutor(
            max_workers=max_workers, thread_name_prefix="media_io"
        )
        self.cpu_executor = ThreadPoolExecutor(
            max_workers=max_workers // 2 or 1, thread_name_prefix="media_cpu"
        )
        self.ffmpeg_executor = ThreadPoolExecutor(
            max_workers=max_workers // 2 or 1, thread_name_prefix="ffmpeg"
        )

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.default_processing = ProcessingSettings()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._hw_detector = HardwareAccelerationDetector(config)
        self._metadata_extractor = MetadataExtractor(self.io_executor)
        self._validator = MediaValidator(self.io_executor)
        self._cache = MediaCache(cache_manager)

        # Downloader –±—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–æ—Å–ª–µ start()
        self._downloader: Optional[MediaDownloader] = None

        # –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã –±—É–¥—É—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø–æ—Å–ª–µ start()
        self._video_processor: Optional[VideoProcessor] = None
        self._audio_processor: Optional[AudioProcessor] = None
        self._image_processor: Optional[ImageProcessor] = None

        # –¢—Ä–∞–Ω—Å–∫—Ä–∞–π–±–µ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è)
        self._transcriber = None

        # –û—á–µ—Ä–µ–¥—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self._processing_queue: asyncio.Queue = asyncio.Queue()

        # üöÄ Deferred Processing Queue
        self._pending_tasks: List[ProcessingTask] = []

        # üöÄ Background Download Queue (async media downloads)
        self._download_queue: Optional[MediaDownloadQueue] = None

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._processed_files = 0
        self._cache_hits = 0
        self._total_processing_time = 0.0
        self._bytes_processed = 0

        # ‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ (Phase 2 Task 2.3)
        self._failed_tasks = 0  # –°—á—ë—Ç—á–∏–∫ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–¥–∞—á
        self._worker_errors: Dict[str, List[str]] = {}  # –û—à–∏–±–∫–∏ –ø–æ –≤–æ—Ä–∫–µ—Ä—É
        self._failed_items_log: List[
            Dict[str, Any]
        ] = []  # –õ–æ–≥ failed items –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self._shutdown_event = asyncio.Event()
        self._worker_tasks: List[asyncio.Task] = []
        self._hw_acceleration_ready = False

        logger.info("MediaProcessor initialized with modular architecture")

    async def start(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∏ –∑–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–æ–≤."""
        try:
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–ø–ø–∞—Ä–∞—Ç–Ω–æ–≥–æ —É—Å–∫–æ—Ä–µ–Ω–∏—è
            try:
                available_encoders = (
                    await self._hw_detector.detect_hardware_acceleration()
                )
                self._hw_acceleration_ready = available_encoders.get("vaapi", False)

                if self._hw_acceleration_ready:
                    logger.info("VA-API hardware acceleration is ready")
                else:
                    logger.info("VA-API not available, using software encoding only")
            except Exception as e:
                logger.warning(f"Hardware acceleration detection failed: {e}")
                self._hw_acceleration_ready = False

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è downloader
            self._downloader = MediaDownloader(
                connection_manager=self.connection_manager,
                temp_dir=self.temp_dir,
                client=self.client,
                worker_clients=self.worker_clients,
            )

            # üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Background Download Queue (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
            if getattr(self.config, "async_media_download", True):
                workers = getattr(self.config, "async_download_workers", 3)
                self._download_queue = MediaDownloadQueue(
                    downloader=self._downloader,
                    max_workers=workers,
                    max_queue_size=1000,
                )
                await self._download_queue.start()
                logger.info(f"üöÄ Background download queue started with {workers} workers")

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
            self._video_processor = VideoProcessor(
                io_executor=self.io_executor,
                cpu_executor=self.cpu_executor,
                hw_detector=self._hw_detector,
                metadata_extractor=self._metadata_extractor,
                config=self.config,
                settings=self.default_processing,
            )

            self._audio_processor = AudioProcessor(
                io_executor=self.io_executor,
                cpu_executor=self.cpu_executor,
                validator=self._validator,
                config=self.config,
                settings=self.default_processing,
            )

            self._image_processor = ImageProcessor(
                io_executor=self.io_executor,
                cpu_executor=self.cpu_executor,
                config=self.config,
                settings=self.default_processing,
            )

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∞–π–±–µ—Ä–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ) - v5.0.0
            transcription_config = getattr(self.config, "transcription", None)
            if transcription_config and transcription_config.enabled:
                try:
                    from .processors import WhisperTranscriber

                    logger.info(
                        f"Initializing Whisper transcriber: "
                        f"device={transcription_config.device}, "
                        f"compute_type={transcription_config.compute_type}"
                    )

                    # Create transcriber
                    self._transcriber = WhisperTranscriber(
                        device=transcription_config.device,
                        compute_type=transcription_config.compute_type,
                        batch_size=transcription_config.batch_size,
                        duration_threshold=transcription_config.duration_threshold,
                        use_batched=transcription_config.use_batched,
                        enable_cache=transcription_config.cache_enabled,
                    )

                    # Lazy loading: model will be loaded on first transcription request
                    logger.info("Transcriber configured (model will load on first use)")

                except Exception as e:
                    logger.error(f"Failed to initialize transcriber: {e}")
                    logger.warning("Transcription will be disabled for this session")
                    self._transcriber = None

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
            try:
                await self._video_processor.initialize()
            except Exception as e:
                logger.warning(f"Video processor initialization failed: {e}")
                logger.info("Video processing will use fallback mode")

            # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤
            for i in range(self.max_workers):
                task = asyncio.create_task(self._processing_worker(f"worker_{i}"))
                self._worker_tasks.append(task)

            logger.info(f"Media processor started with {self.max_workers} workers")

        except Exception as e:
            logger.error(f"Failed to start media processor: {e}")
            self._hw_acceleration_ready = False
            raise

    async def get_media_metadata(self, message: Message) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–µ–¥–∏–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞.

        Args:
            message: Telegram —Å–æ–æ–±—â–µ–Ω–∏–µ

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ None
        """
        if not message.file:
            return None

        try:
            metadata = {
                "size": message.file.size,
                "mime_type": message.file.mime_type,
                "name": message.file.name,
                "attributes": getattr(message.file, "attributes", None),
            }
            return metadata
        except Exception as e:
            logger.error(f"Error getting media metadata for message {message.id}: {e}")
            return None

    async def download_and_process_media(
        self,
        message: Message,
        entity_id: Union[str, int],
        entity_media_path: Path,
        progress_queue=None,
        task_id=None,
        processing_settings: Optional[ProcessingSettings] = None,
    ) -> List[Path]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–µ–¥–∏–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è.

        Args:
            message: Telegram —Å–æ–æ–±—â–µ–Ω–∏–µ
            entity_id: ID —Å—É—â–Ω–æ—Å—Ç–∏ (–∫–∞–Ω–∞–ª/—á–∞—Ç)
            entity_media_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ–¥–∏–∞
            progress_queue: –û—á–µ—Ä–µ–¥—å –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            task_id: ID –∑–∞–¥–∞—á–∏
            processing_settings: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º (–∏–ª–∏ placeholder-–ø—É—Ç–µ–π –ø—Ä–∏ async mode)
        """
        if not self.config.any_media_download_enabled:
            return []

        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–µ–¥–∏–∞
            media_items = await self._extract_media_from_message(message)
            if not media_items:
                return []

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            proc_settings = processing_settings or self.default_processing

            # üöÄ Async Download Mode: queue downloads instead of waiting
            if self._download_queue:
                return await self._queue_media_downloads(
                    media_items, entity_id, entity_media_path
                )

            # Synchronous mode (fallback): process each media file
            tasks = []
            for media_type, msg in media_items:
                task = self._process_single_media(
                    msg,
                    entity_id,
                    media_type,
                    entity_media_path,
                    proc_settings,
                    progress_queue,
                    task_id,
                )
                tasks.append(task)

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            successful_paths = []
            for result in results:
                if isinstance(result, Path) and result.exists():
                    successful_paths.append(result)
                elif isinstance(result, Exception):
                    logger.warning(f"Media processing failed: {result}")

            return successful_paths

        except Exception as e:
            logger.error(
                f"Failed to download and process media for message {message.id}: {e}"
            )
            return []

    async def _queue_media_downloads(
        self,
        media_items: List[Tuple[str, Message]],
        entity_id: Union[str, int],
        entity_media_path: Path,
    ) -> List[Path]:
        """
        Queue media downloads to background workers.
        
        Returns placeholder paths immediately - actual files will be downloaded
        by background workers.
        """
        result_paths = []
        
        for media_type, msg in media_items:
            try:
                # Check if file already exists
                if not hasattr(msg, "file") or not msg.file:
                    continue
                    
                # Generate filename
                filename = await self._generate_filename(msg, media_type)
                if not filename:
                    continue
                
                # Output path
                type_subdir = entity_media_path / media_type
                await aiofiles.os.makedirs(type_subdir, exist_ok=True)
                output_path = type_subdir / filename
                
                # Skip if file already exists with correct size
                if output_path.exists():
                    expected_size = getattr(msg.file, "size", 0)
                    try:
                        actual_size = output_path.stat().st_size
                        if expected_size > 0 and actual_size >= expected_size * 0.95:
                            logger.debug(f"File already exists: {output_path}")
                            result_paths.append(output_path)
                            continue
                    except Exception:
                        pass
                
                # Check cache
                if self.enable_smart_caching:
                    cached_path = await self._cache.check_cache(msg.id, output_path)
                    if cached_path:
                        self._cache_hits += 1
                        result_paths.append(cached_path)
                        continue
                
                # Queue for background download
                await self._download_queue.enqueue(
                    message=msg,
                    entity_id=entity_id,
                    output_path=output_path,
                    media_type=media_type,
                )
                
                # Return the expected output path (file will appear later)
                result_paths.append(output_path)
                
            except Exception as e:
                logger.warning(f"Failed to queue media download: {e}")
        
        return result_paths

    async def _extract_media_from_message(
        self, message: Message
    ) -> List[Tuple[str, Message]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ–¥–∏–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è."""
        media_items: List[Tuple[str, Message]] = []

        if not hasattr(message, "media") or not message.media:
            return media_items

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–µ–¥–∏–∞
        media_type = self._determine_media_type(message)

        # Check extension filters first (tdl-style)
        filename = await self._generate_filename(message, media_type or "unknown")
        if filename and not self._is_extension_allowed(filename):
            logger.debug(f"Skipping {filename} due to extension filter")
            return media_items

        if media_type and self._should_download_media_type(media_type):
            media_items.append((media_type, message))
        else:
            logger.debug(f"Skipping media type {media_type} (disabled in config)")

        return media_items

    def _is_extension_allowed(self, filename: str) -> bool:
        """Check if file extension is allowed by include/exclude lists."""
        if not filename:
            return True

        # Extract extension without dot
        parts = filename.rsplit(".", 1)
        if len(parts) < 2:
            return True  # No extension, allow by default (or maybe filter?)

        ext = parts[1].lower()

        # Exclude takes precedence
        if self.config.exclude_extensions and ext in self.config.exclude_extensions:
            return False

        # Include acts as a whitelist if present
        if self.config.include_extensions and ext not in self.config.include_extensions:
            return False

        return True

    def _should_download_media_type(self, media_type: str) -> bool:
        """Check if the given media type should be downloaded based on config."""
        if media_type in ["photo", "image"]:
            return self.config.download_photos
        elif media_type == "video":
            return self.config.download_videos
        elif media_type == "audio":
            return self.config.download_audio
        else:
            # "document", "webpage", "unknown", stickers, etc.
            return self.config.download_other

    def _determine_media_type(self, message: Message) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–µ–¥–∏–∞."""
        if not hasattr(message, "media") or not message.media:
            return None

        media = message.media
        media_type = type(media).__name__

        if media_type == "MessageMediaPhoto":
            return "photo"
        elif media_type == "MessageMediaDocument":
            if hasattr(media, "document") and media.document:
                mime_type = getattr(media.document, "mime_type", "")
                if mime_type.startswith("video/"):
                    return "video"
                elif mime_type.startswith("audio/"):
                    return "audio"
                elif mime_type.startswith("image/"):
                    return "image"
                else:
                    return "document"
        elif media_type == "MessageMediaWebPage":
            return "webpage"

        return "unknown"

    async def _process_single_media(
        self,
        message: Message,
        entity_id: Union[str, int],
        media_type: str,
        entity_media_path: Path,
        processing_settings: ProcessingSettings,
        progress_queue=None,
        task_id=None,
    ) -> Optional[Path]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –º–µ–¥–∏–∞ —Ñ–∞–π–ª–∞."""
        try:
            # Check if message has file attribute
            if not hasattr(message, "file") or not message.file:
                logger.warning(
                    f"Message {message.id} has no file attribute or file is None"
                )
                return None

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            filename = await self._generate_filename(message, media_type)
            if not filename:
                return None

            # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            type_subdir = entity_media_path / media_type
            await aiofiles.os.makedirs(type_subdir, exist_ok=True)
            output_path = type_subdir / filename

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
            if output_path.exists():
                # Check if we should have processed this file
                should_process = False
                if media_type == "video" and getattr(
                    self.config, "process_video", False
                ):
                    should_process = True
                elif media_type == "audio" and getattr(
                    self.config, "process_audio", True
                ):
                    should_process = True
                elif media_type in ["photo", "image"] and getattr(
                    self.config, "process_images", True
                ):
                    should_process = True

                # If not processing, verify size
                if not should_process:
                    expected_size = (
                        getattr(message.file, "size", 0)
                        if hasattr(message, "file")
                        else 0
                    )
                    stat = output_path.stat()
                    if expected_size > 0 and stat.st_size != expected_size:
                        logger.warning(
                            f"File exists but size mismatch: {stat.st_size} != {expected_size}. Re-downloading."
                        )
                        # Fall through to download
                    else:
                        logger.debug(
                            f"Media file already exists and size matches: {output_path}"
                        )
                        return output_path
                else:
                    # If processing is enabled, we assume existing file is correct if non-zero
                    if output_path.stat().st_size > 0:
                        logger.debug(
                            f"Processed media file already exists: {output_path}"
                        )
                        return output_path

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
            if self.enable_smart_caching:
                cached_path = await self._cache.check_cache(message.id, output_path)
                if cached_path:
                    self._cache_hits += 1
                    return cached_path

            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ MediaDownloader
            if not self._downloader:
                logger.error("MediaDownloader not initialized")
                return None

            temp_path = await self._downloader.download_media(
                message=message,
                progress_queue=progress_queue,
                task_id=task_id,
            )

            if not temp_path or not temp_path.exists():
                logger.error("Download failed")
                return None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            downloaded_size = temp_path.stat().st_size
            expected_size = (
                getattr(message.file, "size", 0) if hasattr(message, "file") else 0
            )

            if expected_size > 0 and downloaded_size < expected_size * 0.95:
                logger.error(
                    f"Downloaded file is incomplete! Downloaded: {downloaded_size} bytes, "
                    f"Expected: {expected_size} bytes ({(downloaded_size / expected_size) * 100:.1f}%)"
                )
                return None

            logger.info(
                f"File downloaded successfully: {downloaded_size / 1024 / 1024:.1f}MB"
            )

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ MetadataExtractor
            # Only try to extract metadata if file is not empty
            if downloaded_size > 0:
                metadata = await self._metadata_extractor.get_metadata(
                    temp_path, media_type
                )
            else:
                metadata = None

            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            processing_task = ProcessingTask(
                input_path=temp_path,
                output_path=output_path,
                media_type=media_type,
                processing_settings=processing_settings,
                metadata=metadata,
            )

            # üöÄ Deferred Processing Logic
            if self.config.deferred_processing:
                # Move temp file to final location immediately (raw)
                # We will process it in-place later
                try:
                    # Ensure parent dir exists
                    await aiofiles.os.makedirs(output_path.parent, exist_ok=True)

                    # Move file
                    shutil.move(str(temp_path), str(output_path))

                    # Update task to point to the new location as input
                    processing_task.input_path = output_path

                    # Add to pending list
                    self._pending_tasks.append(processing_task)

                    logger.info(f"Deferred processing for {filename}. Saved raw file.")
                    return output_path
                except Exception as e:
                    logger.error(f"Failed to move deferred file: {e}")
                    return None

            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –æ—á–µ—Ä–µ–¥—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
            await self._processing_queue.put(processing_task)

            # –û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result_path = await self._wait_for_processing_result(processing_task)

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if result_path and result_path.exists():
                result_size = result_path.stat().st_size

                if result_size == 0:
                    logger.error("Result file is empty! Processing may have failed.")
                    return None

                if expected_size > 0 and result_size < expected_size * 0.01:
                    logger.error(
                        f"Result file suspiciously small! Result: {result_size} bytes"
                    )
                    return None

                self._processed_files += 1
                self._bytes_processed += result_size

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
                if self.enable_smart_caching:
                    await self._cache.save_to_cache(message.id, result_path)

                logger.info(
                    f"Media processing completed: {result_size / 1024 / 1024:.1f}MB -> {result_path}"
                )

                # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                try:
                    if temp_path and temp_path.exists():
                        await aiofiles.os.unlink(temp_path)
                except Exception as e:
                    logger.warning(f"Failed to cleanup temp file {temp_path}: {e}")

                return result_path
            else:
                logger.error("Processing failed or result file not found")
                return None

        except Exception as e:
            logger.error(f"Failed to process media for message {message.id}: {e}")
            return None

    async def _generate_filename(
        self, message: Message, media_type: str
    ) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
        try:
            base_name = f"msg_{message.id}"

            extension_map = {
                "photo": ".jpg",
                "image": ".jpg",
                "video": ".mp4",
                "audio": ".mp3",
                "document": "",
            }

            extension = extension_map.get(media_type, "")

            # Try to get extension from mime_type
            if hasattr(message, "file") and hasattr(message.file, "mime_type"):
                import mimetypes

                ext = mimetypes.guess_extension(message.file.mime_type)
                if ext:
                    extension = ext

            # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            if hasattr(message, "media") and hasattr(message.media, "document"):
                document = message.media.document
                if hasattr(document, "attributes"):
                    for attr in document.attributes:
                        if hasattr(attr, "file_name") and attr.file_name:
                            original_name = sanitize_filename(attr.file_name)
                            name, ext = os.path.splitext(original_name)
                            return f"{base_name}_{name}{ext}"

            return f"{base_name}{extension}"

        except Exception as e:
            logger.error(f"Failed to generate filename: {e}")
            return f"msg_{message.id}.bin"

    async def _wait_for_processing_result(self, task: ProcessingTask) -> Optional[Path]:
        """–û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è."""
        max_wait = 300  # 5 –º–∏–Ω—É—Ç
        check_interval = 1
        last_size = 0
        stable_count = 0
        required_stable_checks = 3

        logger.debug(f"Waiting for processing result: {task.output_path}")

        for attempt in range(max_wait):
            if task.output_path.exists():
                current_size = task.output_path.stat().st_size

                if current_size == last_size and current_size > 0:
                    stable_count += 1
                    if stable_count >= required_stable_checks:
                        logger.debug(
                            f"Processing completed: {current_size / 1024 / 1024:.1f}MB"
                        )
                        return task.output_path
                else:
                    stable_count = 0
                    last_size = current_size

            await asyncio.sleep(check_interval)

        logger.warning(f"Processing timeout for {task.output_path}")
        return task.output_path if task.output_path.exists() else None

    def _handle_worker_error(
        self,
        worker_name: str,
        task: Optional[ProcessingTask],
        error: Exception,
        error_type: str = "task",
    ):
        """
        –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≤–æ—Ä–∫–µ—Ä–∞ (Phase 2 Task 2.3).

        Args:
            worker_name: –ò–º—è –≤–æ—Ä–∫–µ—Ä–∞
            task: –ó–∞–¥–∞—á–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å None –¥–ª—è –æ—à–∏–±–æ–∫ –æ—á–µ—Ä–µ–¥–∏)
            error: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ
            error_type: "queue", "task", –∏–ª–∏ "worker"
        """
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–ª–Ω—ã–º traceback
        if error_type == "queue":
            logger.warning(f"Worker {worker_name}: Queue timeout, continuing...")
        elif error_type == "task":
            logger.error(
                f"Worker {worker_name}: Task failed (File: {task.input_path.name if task else 'N/A'}), "
                f"Type: {task.media_type if task else 'N/A'}, "
                f"Attempt: {task.attempts if task else 'N/A'}, "
                f"Error: {error}"
            )
            # Log full traceback for task errors in DEBUG mode
            logger.opt(exception=True).debug(f"Task error details:")
            self._failed_tasks += 1

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ failed items
            if task:
                self._failed_items_log.append(
                    {
                        "task_file": task.input_path.name,
                        "media_type": task.media_type,
                        "input_path": str(task.input_path),
                        "error": str(error),
                        "timestamp": time.time(),
                        "attempts": task.attempts,
                    }
                )
        else:  # worker error - these are unexpected and should show full trace
            logger.error(
                f"Worker {worker_name}: Unexpected error: {type(error).__name__}: {error}"
            )
            # ALWAYS log full traceback for worker errors (not just in DEBUG)
            logger.opt(exception=True).error(f"Worker error traceback:")

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –æ—à–∏–±–æ–∫ –ø–æ –≤–æ—Ä–∫–µ—Ä—É
        if worker_name not in self._worker_errors:
            self._worker_errors[worker_name] = []
        self._worker_errors[worker_name].append(f"{error_type}: {str(error)}")

        # ÈôêÂà∂—Ä–∞–∑–º–µ—Ä –ª–æ–≥–∞ (–Ω–µ –±–æ–ª–µ–µ 100 –æ—à–∏–±–æ–∫ –Ω–∞ –≤–æ—Ä–∫–µ—Ä)
        if len(self._worker_errors[worker_name]) > 100:
            self._worker_errors[worker_name] = self._worker_errors[worker_name][-100:]

    async def _processing_worker(self, worker_name: str):
        """
        –§–æ–Ω–æ–≤—ã–π –≤–æ—Ä–∫–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞ (Phase 2 Task 2.3: Enhanced error handling).
        """
        logger.debug(f"Processing worker {worker_name} started")

        while not self._shutdown_event.is_set():
            task = None  # –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ finally –±–ª–æ–∫–µ
            try:
                # –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                try:
                    task = await asyncio.wait_for(
                        self._processing_queue.get(), timeout=1.0
                    )
                except asyncio.TimeoutError:
                    # –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ - –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∂–¥–∞—Ç—å
                    continue

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏
                start_time = time.time()

                try:
                    success = await self._execute_processing_task(task, worker_name)

                    processing_time = time.time() - start_time
                    self._total_processing_time += processing_time

                    if success:
                        logger.debug(
                            f"Worker {worker_name} completed task {task.input_path.name} in {processing_time:.2f}s"
                        )
                    else:
                        # –ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ—É–¥–∞—á–µ–Ω - –ø—ã—Ç–∞–µ–º—Å—è retry
                        task.attempts += 1
                        if task.attempts < task.max_attempts:
                            logger.warning(
                                f"Worker {worker_name}: Task {task.input_path.name} retry "
                                f"{task.attempts}/{task.max_attempts}"
                            )
                            await self._processing_queue.put(task)
                        else:
                            # Max retries –¥–æ—Å—Ç–∏–≥–Ω—É—Ç
                            logger.error(
                                f"Worker {worker_name}: Task {task.input_path.name} failed after "
                                f"{task.attempts} attempts, giving up"
                            )
                            self._handle_worker_error(
                                worker_name,
                                task,
                                Exception("Max retries exceeded"),
                                "task",
                            )

                except Exception as e:
                    # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    self._handle_worker_error(worker_name, task, e, "task")

                    task.attempts += 1
                    if task.attempts < task.max_attempts:
                        logger.info(
                            f"Requeueing task {task.input_path.name} for retry (attempt {task.attempts}/{task.max_attempts})"
                        )
                        await self._processing_queue.put(task)

                finally:
                    # –í–∞–∂–Ω–æ: –≤—Å–µ–≥–¥–∞ –≤—ã–∑—ã–≤–∞–µ–º task_done, –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
                    if task:
                        try:
                            self._processing_queue.task_done()
                        except ValueError:
                            # task_done() —É–∂–µ –±—ã–ª –≤—ã–∑–≤–∞–Ω –∏–ª–∏ –æ—á–µ—Ä–µ–¥—å –±—ã–ª–∞ –æ—á–∏—â–µ–Ω–∞
                            pass

            except Exception as e:
                # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ worker loop (–Ω–µ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–¥–∞—á–∏)
                self._handle_worker_error(worker_name, task, e, "worker")
                await asyncio.sleep(1)

        logger.debug(f"Processing worker {worker_name} stopped")

    async def _execute_processing_task(
        self, task: ProcessingTask, worker_name: str
    ) -> bool:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        try:
            if not task.input_path.exists():
                logger.error(f"Input file not found: {task.input_path}")
                return False

            source_size = task.input_path.stat().st_size
            success = False

            # –í—ã–±–æ—Ä –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –ø–æ —Ç–∏–ø—É –º–µ–¥–∏–∞
            if task.media_type == "video":
                if not self._video_processor:
                    logger.error("VideoProcessor not initialized")
                    return False
                success = await self._video_processor.process(task, worker_name)

            elif task.media_type == "audio":
                if not self._audio_processor:
                    logger.error("AudioProcessor not initialized")
                    return False
                success = await self._audio_processor.process(task, worker_name)

            elif task.media_type in ["photo", "image"]:
                if not self._image_processor:
                    logger.error("ImageProcessor not initialized")
                    return False
                success = await self._image_processor.process(task, worker_name)

            else:
                # –ü—Ä–æ—Å—Ç–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤
                logger.info(f"Unknown media type {task.media_type}, copying file")
                success = await self._copy_file(task)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if success and task.output_path.exists():
                result_size = task.output_path.stat().st_size

                if result_size < source_size * 0.01:
                    logger.warning(
                        "Processing produced suspicious result, using fallback copy"
                    )
                    success = await self._copy_file(task)
                elif result_size == 0:
                    logger.warning(
                        "Processing produced empty file, using fallback copy"
                    )
                    success = await self._copy_file(task)

            elif success:
                logger.warning("Processing claimed success but no output file found")
                success = await self._copy_file(task)

            return success

        except Exception as e:
            logger.error(f"Task execution failed: {e}")
            try:
                logger.info("Attempting fallback file copy...")
                return await self._copy_file(task)
            except Exception as e2:
                logger.error(f"Fallback copy also failed: {e2}")
                return False

    async def _copy_file(self, task: ProcessingTask) -> bool:
        """–ü—Ä–æ—Å—Ç–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø—Ä–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        try:
            async with aiofiles.open(task.input_path, "rb") as src:
                async with aiofiles.open(task.output_path, "wb") as dst:
                    while chunk := await src.read(8192 * 1024):
                        await dst.write(chunk)

            if task.output_path.exists() and task.output_path.stat().st_size > 0:
                logger.info(f"File copied successfully: {task.output_path}")
                return True

            return False

        except Exception as e:
            logger.error(f"File copy failed: {e}")
            return False

    async def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞."""
        avg_processing_time = self._total_processing_time / max(
            self._processed_files, 1
        )

        cache_hit_rate = (
            self._cache_hits / max(self._processed_files + self._cache_hits, 1) * 100
        )

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        stats = {
            "processed_files": self._processed_files,
            "cache_hits": self._cache_hits,
            "cache_hit_rate_percent": cache_hit_rate,
            "avg_processing_time_seconds": avg_processing_time,
            "total_bytes_processed": self._bytes_processed,
            "hardware_acceleration": self._hw_detector.available_encoders,
            "queue_size": self._processing_queue.qsize(),
            "active_workers": len([t for t in self._worker_tasks if not t.done()]),
        }

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç downloader
        if self._downloader:
            stats["downloader"] = self._downloader.get_statistics()

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
        if self._video_processor:
            stats["video_processor"] = self._video_processor.get_statistics()

        if self._audio_processor:
            stats["audio_processor"] = self._audio_processor.get_statistics()

        if self._image_processor:
            stats["image_processor"] = self._image_processor.get_statistics()

        return stats

    async def is_idle(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ª–∏ –≤—Å—è —Ä–∞–±–æ—Ç–∞ –º–µ–¥–∏–∞-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞.

        Returns:
            True –µ—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞ –∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        # Check processing queue
        if self._processing_queue.qsize() > 0:
            return False

        # üöÄ Check download queue
        if self._download_queue:
            pending = self._download_queue.get_pending_count()
            in_progress = self._download_queue.get_in_progress_count()
            if pending > 0 or in_progress > 0:
                return False

        try:
            await asyncio.wait_for(self._processing_queue.join(), timeout=0.1)
            return True
        except asyncio.TimeoutError:
            return False

    async def wait_for_downloads(self, timeout: Optional[float] = None) -> bool:
        """
        Wait for all background downloads to complete.
        
        Args:
            timeout: Maximum time to wait (None = wait forever)
            
        Returns:
            True if all downloads completed, False if timeout
        """
        if not self._download_queue:
            return True
            
        logger.info("‚è≥ Waiting for background downloads to complete...")
        result = await self._download_queue.wait_all(timeout=timeout)
        
        if result:
            self._download_queue.log_stats()
            logger.info("‚úÖ All downloads completed")
        else:
            self._download_queue.log_stats()
            logger.warning("‚ö†Ô∏è Download wait timed out")
            
        return result

    async def wait_until_idle(
        self, timeout: float = 300.0, progress_callback=None
    ) -> bool:
        """
        –û–∂–∏–¥–∞–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á –º–µ–¥–∏–∞-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞.

        Args:
            timeout: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            progress_callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

        Returns:
            True –µ—Å–ª–∏ –≤—Å–µ –∑–∞–¥–∞—á–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã, False –ø—Ä–∏ —Ç–∞–π–º–∞—É—Ç–µ
        """
        start_time = time.time()
        last_progress_time = start_time

        while time.time() - start_time < timeout:
            if await self.is_idle():
                return True

            current_time = time.time()
            if current_time - last_progress_time >= 15.0:
                elapsed = current_time - start_time
                queue_size = self._processing_queue.qsize()

                stats = await self.get_stats()
                active_workers = stats.get("active_workers", 0)

                if progress_callback:
                    progress_callback(queue_size, elapsed)
                else:
                    logger.info(
                        f"Media processor still working: queue={queue_size}, "
                        f"active_workers={active_workers}, waited={elapsed:.0f}s"
                    )

                last_progress_time = current_time

            await asyncio.sleep(10.0)

        return False

    async def process_pending_tasks(self):
        """
        Process all deferred media tasks.
        Should be called after the main export loop.
        """
        if not self._pending_tasks:
            logger.info("No pending media tasks to process.")
            return

        total = len(self._pending_tasks)
        logger.info(f"üöÄ Starting deferred processing for {total} files...")

        for i, task in enumerate(self._pending_tasks):
            try:
                final_path = task.output_path
                if final_path.exists():
                    # Create a temp file for processing input
                    temp_input = final_path.with_suffix(final_path.suffix + ".tmp_proc")
                    shutil.move(str(final_path), str(temp_input))
                    task.input_path = temp_input

                    # Add to queue
                    await self._processing_queue.put(task)
                else:
                    logger.warning(f"Pending file missing: {final_path}")
            except Exception as e:
                logger.error(f"Failed to prepare deferred task: {e}")

        # Clear pending list
        self._pending_tasks.clear()

        # Wait for all to finish
        await self.wait_until_idle()
        logger.info("‚úÖ Deferred processing complete.")

    async def transcribe_audio(self, file_path: Path) -> Optional[str]:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª (–≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ).

        Version: 5.0.0 - Simplified standalone implementation

        Args:
            file_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É

        Returns:
            –¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if not self._transcriber:
            logger.debug("Transcriber not available")
            return None

        try:
            # Get language from config
            language = getattr(self.config.transcription, "language", None)

            # Run transcription in executor to avoid blocking
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self.cpu_executor,
                lambda: self._transcriber.transcribe(file_path, language=language),
            )

            if result and result.text:
                logger.debug(
                    f"Transcription successful: {file_path.name} "
                    f"({len(result.text)} chars, language={result.language})"
                )
                return result.text
            else:
                logger.warning(
                    f"Transcription returned empty result for {file_path.name}"
                )
                return None

        except Exception as e:
            logger.error(f"Transcription failed for {file_path}: {e}")
            return None

    async def shutdown(self, timeout: float = 30.0):
        """
        –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã (Phase 2 Task 2.3: Enhanced shutdown with error logging).
        """
        logger.info("Shutting down media processor...")

        # üöÄ –û—Å—Ç–∞–Ω–æ–≤–∫–∞ Background Download Queue
        if self._download_queue:
            logger.info("Waiting for background downloads to complete...")
            self._download_queue.log_stats()
            await self._download_queue.stop(wait_for_completion=True)
            logger.info("Background download queue stopped")

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—à–∏–±–æ–∫ –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º
        if self._failed_tasks > 0 or self._worker_errors:
            logger.warning(
                f"‚ö†Ô∏è Media processor shutdown with errors: "
                f"failed_tasks={self._failed_tasks}, workers_with_errors={len(self._worker_errors)}"
            )

            for worker_name, errors in self._worker_errors.items():
                logger.warning(f"  Worker '{worker_name}': {len(errors)} error(s)")
                if errors:
                    logger.debug(f"    Last error: {errors[-1]}")

        # –°–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        self._shutdown_event.set()

        # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤–æ—Ä–∫–µ—Ä–æ–≤
        if self._worker_tasks:
            try:
                results = await asyncio.wait_for(
                    asyncio.gather(*self._worker_tasks, return_exceptions=True),
                    timeout=timeout,
                )
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫
                for i, result in enumerate(results):
                    if isinstance(result, Exception):
                        logger.error(f"Worker {i} failed with exception: {result}")
            except asyncio.TimeoutError:
                logger.warning(
                    "Some workers didn't complete within timeout, cancelling..."
                )
                for task in self._worker_tasks:
                    if not task.done():
                        task.cancel()
                        logger.warning(f"Cancelled task: {task.get_name()}")

        # –ó–∞–∫—Ä—ã—Ç–∏–µ –ø—É–ª–æ–≤ –ø–æ—Ç–æ–∫–æ–≤ (Phase 2 Task 2.3: Proper executor shutdown)
        try:
            logger.debug("Shutting down thread executors...")
            self.io_executor.shutdown(wait=True)
            self.cpu_executor.shutdown(wait=True)
            self.ffmpeg_executor.shutdown(wait=True)
            logger.debug("Thread executors shut down successfully")
        except Exception as e:
            logger.error(f"Error during executor shutdown: {e}")

        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        try:
            import shutil

            shutil.rmtree(self.temp_dir, ignore_errors=True)
            logger.debug(f"Cleaned up temp directory: {self.temp_dir}")
        except Exception as e:
            logger.warning(f"Failed to cleanup temp directory: {e}")

        logger.info("Media processor shutdown completed")

    def log_statistics(self):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (Phase 2 Task 2.3: Include error statistics).
        –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏.
        """
        logger.info("=== Media Processor Statistics ===")
        logger.info(f"Processed files: {self._processed_files}")
        logger.info(f"Cache hits: {self._cache_hits}")
        logger.info(f"Total bytes processed: {self._bytes_processed}")

        # ‚ö†Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫ (Phase 2 Task 2.3)
        logger.info(f"Failed tasks: {self._failed_tasks}")
        if self._worker_errors:
            logger.info(f"Workers with errors: {len(self._worker_errors)}")
            for worker_name, errors in self._worker_errors.items():
                logger.info(f"  {worker_name}: {len(errors)} error(s)")
        if self._failed_items_log:
            logger.info(f"Failed items logged: {len(self._failed_items_log)}")

        if self._downloader:
            self._downloader.log_statistics()

        # üöÄ Download Queue Statistics
        if self._download_queue:
            self._download_queue.log_stats()

        if self._video_processor:
            self._video_processor.log_statistics()

        if self._audio_processor:
            self._audio_processor.log_statistics()

        if self._image_processor:
            self._image_processor.log_statistics()

    def get_error_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—à–∏–±–æ–∫ (Phase 2 Task 2.3).

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –æ—à–∏–±–∫–∞—Ö
        """
        return {
            "failed_tasks": self._failed_tasks,
            "worker_errors": dict(self._worker_errors),
            "failed_items_log": self._failed_items_log,
            "total_workers_with_errors": len(self._worker_errors),
        }
